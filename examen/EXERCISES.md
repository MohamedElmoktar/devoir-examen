# üìù Exercices Pratiques - Pr√©paration Examen

Exercices avec solutions pour ma√Ætriser le projet

---

## EXERCICE 1 : Calcul FedAvg √† la main

**√ânonc√© :**
3 Edge nodes entra√Ænent localement et obtiennent :
- Edge 1 : 100 samples, coef = [2.0, 3.0], intercept = 0.5
- Edge 2 : 200 samples, coef = [3.0, 4.0], intercept = 1.0
- Edge 3 : 50 samples, coef = [1.0, 2.0], intercept = 0.0

Calculez les poids du mod√®le global apr√®s FedAvg.

**Solution :**
```
Total samples = 100 + 200 + 50 = 350

Poids Edge 1 = 100/350 = 0.286
Poids Edge 2 = 200/350 = 0.571
Poids Edge 3 = 50/350 = 0.143

coef[0] = 0.286 √ó 2.0 + 0.571 √ó 3.0 + 0.143 √ó 1.0
        = 0.572 + 1.713 + 0.143
        = 2.428

coef[1] = 0.286 √ó 3.0 + 0.571 √ó 4.0 + 0.143 √ó 2.0
        = 0.858 + 2.284 + 0.286
        = 3.428

intercept = 0.286 √ó 0.5 + 0.571 √ó 1.0 + 0.143 √ó 0.0
          = 0.143 + 0.571 + 0.0
          = 0.714

R√âPONSE :
coef = [2.428, 3.428]
intercept = 0.714
```

---

## EXERCICE 2 : Normalisation Z-score

**√ânonc√© :**
Un capteur mesure V=250V et I=15A.
Param√®tres normaux : Œº_V=230V, œÉ_V=5V, Œº_I=10A, œÉ_I=2A

Calculez les features normalis√©es.

**Solution :**
```
V_norm = (V - Œº_V) / œÉ_V
       = (250 - 230) / 5
       = 20 / 5
       = 4.0

I_norm = (I - Œº_I) / œÉ_I
       = (15 - 10) / 2
       = 5 / 2
       = 2.5

P = V √ó I = 250 √ó 15 = 3750W
P_norm = (P - Œº_P) / œÉ_P
       = (3750 - 2300) / 1000
       = 1.45

Features = [4.0, 2.5, 1.45]

INTERPR√âTATION :
V_norm = 4.0 ‚Üí 4 √©carts-types au-dessus (ANOMALIE !)
I_norm = 2.5 ‚Üí 2.5 √©carts-types au-dessus (ANOMALIE !)
‚Üí Probable surtension + surintensit√©
```

---

## EXERCICE 3 : Calcul bande passante

**√ânonc√© :**
Comparez la bande passante utilis√©e pour 4 villages sur 1 heure entre :
- A) Approche centralis√©e (toutes donn√©es au Cloud)
- B) Federated Learning (poids seulement)

Donn√©es :
- Fr√©quence : 2 msg/s par village
- Taille message brut : 100 bytes
- Taille poids mod√®le : 500 bytes
- Fr√©quence update poids : 1/6s (toutes les 50 lectures)

**Solution :**
```
APPROCHE A (Centralis√©) :
Messages/heure = 4 villages √ó 2 msg/s √ó 3600s = 28,800 messages
Taille totale = 28,800 √ó 100 bytes = 2,880,000 bytes = 2.88 MB

APPROCHE B (Federated Learning) :
Updates/heure = 4 villages √ó (3600s / 6s) = 2,400 updates
Taille totale = 2,400 √ó 500 bytes = 1,200,000 bytes = 1.2 MB

R√âDUCTION :
(2.88 - 1.2) / 2.88 = 58.3% de r√©duction

MAIS ATTENTION !
On oublie les donn√©es locales Edge ‚Üí Fog ‚Üí Cloud
Calcul complet :

Centralis√© :
- Edge ‚Üí Cloud : 2.88 MB

Federated :
- Edge ‚Üí Fog : 1.2 MB (poids)
- Fog ‚Üí Cloud : d√©pend agr√©gation

Si Fog agr√®ge toutes les 30s :
Fog updates = 120 updates/heure (3600s / 30s)
Par r√©gion (2 r√©gions) = 240 updates
Fog ‚Üí Cloud = 240 √ó 1000 bytes = 240 KB

Total FL = 1.2 MB + 0.24 MB = 1.44 MB
R√©duction = 50%
```

---

## EXERCICE 4 : Latence bout en bout

**√ânonc√© :**
Calculez la latence totale pour qu'une anomalie d√©tect√©e par un capteur apparaisse sur le dashboard.

Latences connues :
- Capteur ‚Üí Kafka : 10ms
- Kafka ‚Üí Edge : 20ms
- Edge training : 0ms (d√©j√† entra√Æn√©)
- Edge inference : 5ms
- Edge ‚Üí Kafka : 10ms
- Kafka ‚Üí Fog : 20ms
- Fog aggregation : 30,000ms (fen√™tre 30s)
- Fog ‚Üí Kafka : 10ms
- Kafka ‚Üí Cloud : 20ms
- Cloud FedAvg : 50ms
- Cloud ‚Üí Kafka : 10ms
- Kafka ‚Üí Dashboard : 20ms
- Dashboard render : 100ms

**Solution :**
```
SC√âNARIO 1 : D√©tection locale (Edge)
Capteur ‚Üí Kafka : 10ms
Kafka ‚Üí Edge : 20ms
Edge inference : 5ms
(Edge peut d√©tecter localement, pas besoin d'attendre FedAvg)

TOTAL = 35ms (d√©tection temps r√©el !)

SC√âNARIO 2 : M√©triques sur Dashboard
Capteur ‚Üí Kafka : 10ms
Kafka ‚Üí Edge : 20ms
Edge training : 0ms (batch)
Edge ‚Üí Kafka : 10ms
Kafka ‚Üí Fog : 20ms
Fog aggregation : 30,000ms (goulot !)
Fog ‚Üí Kafka : 10ms
Kafka ‚Üí Cloud : 20ms
Cloud FedAvg : 50ms
Cloud ‚Üí Kafka : 10ms
Kafka ‚Üí Dashboard : 20ms
Dashboard render : 100ms

TOTAL = 30,270ms ‚âà 30 secondes

OPTIMISATION :
Si on r√©duit fen√™tre Fog √† 5s :
TOTAL = 5,270ms ‚âà 5 secondes

CONCLUSION :
D√©tection locale = temps r√©el (<100ms)
M√©triques globales = diff√©r√© (30s)
```

---

## EXERCICE 5 : Choix architecture

**√ânonc√© :**
Pour chaque sc√©nario, justifiez si Federated Learning est adapt√© :

A) R√©seau social avec 1 milliard d'utilisateurs, photos personnelles
B) Station m√©t√©o nationale avec 50 capteurs centralis√©s
C) Smartphones d√©tectant activit√© physique (marche/course) pour 10,000 users
D) Serveurs d'une banque analysant transactions frauduleuses

**Solution :**

**A) R√©seau social (1B users)**
‚úÖ **ADAPT√â** - Federated Learning
- Privacy : photos personnelles sensibles
- Scalabilit√© : impossiblede centraliser 1B users
- Bande passante : photos = gros fichiers
- Exemple : Google Photos utilise FL

**B) Station m√©t√©o (50 capteurs)**
‚ùå **NON ADAPT√â** - Approche centralis√©e
- Privacy : donn√©es m√©t√©o publiques
- Volume : 50 capteurs = g√©rable au Cloud
- Latence : pas critique (pr√©visions √† l'heure)
- Complexit√© : FL serait over-engineering

**C) Smartphones activit√© (10K users)**
‚úÖ **ADAPT√â** - Federated Learning
- Privacy : donn√©es sant√© sensibles (RGPD)
- Offline : d√©tection locale n√©cessaire
- Bande passante : √©conomies importantes
- Exemple : Apple HealthKit utilise FL

**D) Banque transactions (centralis√©)**
‚ùå **NON ADAPT√â** - Approche centralis√©e
- Privacy : d√©j√† g√©r√© par chiffrement + compliance
- Temps r√©el : besoin d√©tection <100ms au datacenter
- R√©gulation : audits n√©cessitent acc√®s donn√©es
- Infrastructure : serveurs bancaires d√©j√† s√©curis√©s

---

## EXERCICE 6 : Debugging

**√ânonc√© :**
Vous lancez le syst√®me mais les Edge nodes ne re√ßoivent aucune donn√©e.
Logs observ√©s :
```
[Simulator] INFO - ‚úì Kafka Producer connect√©
[Simulator] INFO - ‚úì [village_1] V=235V, I=10A
[Edge village_1] INFO - ‚úì Kafka Consumer connect√©
[Edge village_1] WARNING - Aucun message re√ßu depuis 60s
```

Diagnostiquez le probl√®me et proposez une solution.

**Solution :**

**Diagnostic √©tape par √©tape :**

```bash
# 1. V√©rifier que Kafka re√ßoit les messages
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic sensor_data \
  --from-beginning \
  --max-messages 5
```

**Cas 1 : Messages visibles**
‚Üí Probl√®me : Edge consumer mal configur√©

Causes possibles :
- Consumer group diff√©rent avec offset √† la fin
- Filter edge_id incorrect
- Consumer.poll() timeout trop court

Solution :
```python
# edge_node.py
consumer = KafkaConsumer(
    'sensor_data',
    group_id=f'edge_node_{edge_id}',
    auto_offset_reset='earliest',  # Lire depuis d√©but
    consumer_timeout_ms=None  # Pas de timeout
)
```

**Cas 2 : Aucun message visible**
‚Üí Probl√®me : Simulator ne publie pas

Causes possibles :
- Topic pas cr√©√©
- Producer mal configur√©
- Erreur silencieuse

Solution :
```bash
# Cr√©er topics
python create_kafka_topics.py

# V√©rifier topics
docker exec kafka kafka-topics \
  --list --bootstrap-server localhost:9092

# V√©rifier logs simulator
tail -f logs/simulator.log
```

**Cas 3 : Topic existe mais vide**
‚Üí Probl√®me : Serialization ou Producer

Solution :
```python
# simulator.py - ajouter logs debug
try:
    future = producer.send('sensor_data', message)
    record_metadata = future.get(timeout=10)
    logger.info(f"Message envoy√© : {record_metadata.offset}")
except Exception as e:
    logger.error(f"ERREUR : {e}")
```

---

## EXERCICE 7 : Optimisation

**√ânonc√© :**
Le syst√®me fonctionne mais la pr√©cision du mod√®le plafonne √† 60%.
Proposez 3 optimisations pour am√©liorer la performance.

**Solution :**

**1. Augmenter features**
```python
# Actuellement : [V_norm, I_norm, P_norm]
# Ajouter features d√©riv√©es :

def extract_features(history):
    # Features temporelles
    V_mean_5s = np.mean(history[-10:, 0])  # Moyenne 5s
    V_std_5s = np.std(history[-10:, 0])    # Variance
    V_trend = history[-1, 0] - history[-5, 0]  # Tendance

    # Features fr√©quentielles
    V_fft = np.fft.fft(history[:, 0])
    dominant_freq = np.argmax(np.abs(V_fft))

    return [V_norm, I_norm, P_norm,
            V_mean_5s, V_std_5s, V_trend,
            dominant_freq]
```
Gain attendu : +10-15% pr√©cision

**2. Ajuster hyper-param√®tres**
```python
# config.py - Tester diff√©rentes configs

# Configuration actuelle (sous-optimale ?)
MODEL_PARAMS = {
    'learning_rate': 'constant',
    'eta0': 0.01,  # Trop faible ?
    'alpha': 0.0001  # R√©gularisation trop forte ?
}

# Configuration optimis√©e
MODEL_PARAMS = {
    'learning_rate': 'adaptive',  # Ajuste automatiquement
    'eta0': 0.1,  # Plus agressif
    'alpha': 0.00001,  # Moins de r√©gularisation
    'early_stopping': True,
    'validation_fraction': 0.1
}
```
Gain attendu : +5-10% pr√©cision

**3. Augmenter donn√©es d'entra√Ænement**
```python
# Actuellement : 50 samples par batch
# Probl√®me : pas assez pour apprendre patterns complexes

# config.py
EDGE_TRAINING_FREQUENCY = 200  # Au lieu de 50
EDGE_BATCH_SIZE = 100  # Au lieu de 20

# Plus de donn√©es = meilleure g√©n√©ralisation
```
Gain attendu : +5-8% pr√©cision

**BONUS : Class imbalance**
```python
# Si 90% normal, 10% anomalie
# Mod√®le apprend √† toujours pr√©dire "normal"

from sklearn.utils import class_weight

# Calculer poids des classes
weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.array([0, 1]),
    y=labels
)

# Appliquer au mod√®le
model = SGDClassifier(class_weight='balanced')
```
Gain attendu : +10-20% sur d√©tection anomalies

---

## EXERCICE 8 : Scalabilit√©

**√ânonc√© :**
Actuellement 4 villages. Le projet doit passer √† 100 villages.
Identifiez 3 goulots d'√©tranglement et proposez des solutions.

**Solution :**

**Goulot 1 : Kafka partitions**
```
Probl√®me :
- 3 partitions pour 100 villages
- Parallelisme limit√©
- Latence augmente

Solution :
# docker-compose.yml
environment:
  KAFKA_NUM_PARTITIONS: 50  # 50 partitions
  KAFKA_REPLICATION_FACTOR: 3  # R√©silience

# Edge nodes
# Kafka distribue automatiquement sur partitions

Gain : 16√ó parall√©lisme (50 vs 3)
```

**Goulot 2 : Fog Spark (1 instance)**
```
Probl√®me :
- 1 seul worker Spark
- Agr√©gation s√©quentielle
- RAM insuffisante (500 MB ‚Üí 10+ GB)

Solution :
# Spark cluster
spark-submit \
  --master spark://master:7077 \
  --executor-memory 4g \
  --num-executors 10 \
  --executor-cores 4 \
  fog_aggregator_spark.py

# Ou : Spark on Kubernetes
kubectl apply -f spark-deployment.yaml

Gain : 10√ó capacit√© traitement
```

**Goulot 3 : Cloud FedAvg (agr√©gation s√©quentielle)**
```
Probl√®me :
- FedAvg s√©quentiel : O(n)
- 100 villages = 100√ó plus lent

Solution :
# Agr√©gation hi√©rarchique
def hierarchical_fedavg(updates, levels=2):
    # Niveau 1 : 100 villages ‚Üí 10 groupes
    groups = [updates[i:i+10] for i in range(0, 100, 10)]
    regional = [fedavg(group) for group in groups]

    # Niveau 2 : 10 r√©gions ‚Üí 1 global
    return fedavg(regional)

# Complexit√© : O(n/k + k) au lieu de O(n)

Gain : 5√ó plus rapide si k=10
```

**Monitoring scalabilit√© :**
```python
# Ajouter m√©triques
import time

start = time.time()
global_weights = federated_averaging(updates)
duration = time.time() - start

logger.info(f"FedAvg duration: {duration:.2f}s for {len(updates)} updates")

# Alarme si trop lent
if duration > 5.0:
    send_alert("FedAvg trop lent !")
```

---

## ‚úÖ CORRECTION RAPIDE

V√©rifiez vos r√©ponses :
- **Ex1** : coef=[2.428, 3.428], intercept=0.714 ‚úì
- **Ex2** : Features=[4.0, 2.5, 1.45], ANOMALIE ‚úì
- **Ex3** : R√©duction 50% bande passante ‚úì
- **Ex4** : Local=35ms, Global=30s ‚úì
- **Ex5** : A=Oui, B=Non, C=Oui, D=Non ‚úì
- **Ex6** : V√©rifier topics + offsets consumer ‚úì
- **Ex7** : Features + Hyper-params + Data ‚úì
- **Ex8** : Kafka partitions + Spark cluster + Hi√©rarchie ‚úì

**Score 8/8** ‚Üí Vous ma√Ætrisez ! üéâ

---

## üìö Pour aller plus loin

Cr√©ez vos propres exercices :
1. Calculez la convergence th√©orique de FedAvg
2. Impl√©mentez Differential Privacy
3. Comparez FedAvg vs FedProx
4. Simulez une attaque Byzantine
5. Optimisez la compression de mod√®les

R√©visez `EXAM_PREPARATION.md` pour th√©orie compl√®te.
